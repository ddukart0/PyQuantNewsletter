{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccf4c8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000;\"><img src=\"pqn.png\"></img></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f03b97",
   "metadata": {},
   "source": [
    "## Load essential libraries and prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9a387",
   "metadata": {},
   "source": [
    "We start by importing necessary libraries and loading environment variables. This sets up our working environment for using language models and document processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7451e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60223cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c2d27",
   "metadata": {},
   "source": [
    "We import the necessary libraries for interacting with OpenAI's language models and processing documents. The environment variables are loaded using the dotenv library to ensure all configurations are set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8b5aa",
   "metadata": {},
   "source": [
    "## Initialize the language model and load the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a99a4",
   "metadata": {},
   "source": [
    "Next, we initialize the language model and load the NVDA 10-K document for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b52752",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = SimpleDirectoryReader(input_files=[\"nvda.pdf\"]).load_data()\n",
    "print(f\"Loaded NVDA 10-K with {len(doc)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17697040",
   "metadata": {},
   "source": [
    "The language model is set up with specific parameters like temperature and model name. We then load the NVDA 10-K document using SimpleDirectoryReader, which reads the PDF file and prepares it for further processing. The number of pages loaded is printed to confirm successful loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8dc3d",
   "metadata": {},
   "source": [
    "## Create the document index and query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe91744",
   "metadata": {},
   "source": [
    "We create an index from the loaded document and set up a query engine to interact with the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c825ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await engine.aquery(\"What is the revenue of NVDIA in the last period reported? Answer in millions with page reference. Include the period.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9615fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await engine.aquery(\"What is the beginning and end date of NVIDA's fiscal period?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11839c5b",
   "metadata": {},
   "source": [
    "An index is created from the loaded document, which enables quick and efficient searching. We then set up a query engine that will search the document based on similarity to the input queries. By querying the engine, we retrieve specific information such as revenue and fiscal period dates from the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f72de7",
   "metadata": {},
   "source": [
    "## Configure query engine tools for sub-questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8dcdc",
   "metadata": {},
   "source": [
    "We configure tools to handle more complex queries by breaking them down into sub-questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5588b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tool = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=engine, \n",
    "        metadata=ToolMetadata(name='nvda_10k', description='Provides information about NVDA financials for year 2024')\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_engine = SubQuestionQueryEngine.from_defaults(query_engine_tools=query_engine_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62cddb6",
   "metadata": {},
   "source": [
    "We set up tools that will allow the query engine to handle complex questions by splitting them into simpler sub-questions. The metadata provides context about the document being queried. A sub-question query engine is then created using these tools to enhance the querying capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b35c77",
   "metadata": {},
   "source": [
    "## Use the sub-question query engine for detailed queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8e7c0",
   "metadata": {},
   "source": [
    "Finally, we use the sub-question query engine to ask detailed questions about customer segments, geographies, and risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await s_engine.aquery(\"Compare and contrast the customer segments and geographies that grew the fastest\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee077e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await s_engine.aquery(\"What risks to NVDIA's business are highlighted in the document?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31410dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await s_engine.aquery(\"How does NVDIA see the risks highlighted in the document impacting financial performance?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f2e9b",
   "metadata": {},
   "source": [
    "The sub-question query engine is used to ask detailed questions about customer segments, geographies, and business risks. The engine processes these queries by breaking them down into simpler questions and then aggregating the answers. This allows us to extract detailed and nuanced information from the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aa9c0",
   "metadata": {},
   "source": [
    "## Your next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6d881",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "Try changing the document or the type of questions you ask. Experiment with different query parameters to see how the answers change. This will help you get comfortable with using language models for document analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529077d5",
   "metadata": {},
   "source": [
    "<a href=\"https://pyquantnews.com/\">PyQuant News</a> is where finance practitioners level up with Python for quant finance, algorithmic trading, and market data analysis. Looking to get started? Check out the fastest growing, top-selling course to <a href=\"https://gettingstartedwithpythonforquantfinance.com/\">get started with Python for quant finance</a>. For educational purposes. Not investment advise. Use at your own risk."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
